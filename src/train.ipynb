{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from config import CFG\n",
    "import dataset\n",
    "import engine\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "if not os.path.exists('model_checkpoints/base_model/'):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(CFG.model_name)\n",
    "    model.save_pretrained('model_checkpoints/base_model')\n",
    "else:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained('model_checkpoints/base_model/')\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "raw_dataset = load_dataset(\"europa_eac_tm\", language_pair=(\"pl\", \"en\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration pl2en-0da2ec5e9ea613fc\n",
      "Reusing dataset europa_eac_tm (/home/bartek/.cache/huggingface/datasets/europa_eac_tm/pl2en-0da2ec5e9ea613fc/0.0.0/955b2501a836c2ea49cfe3e719aec65dcbbc3356bbbe53cf46f08406eb77386a)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X = [i['translation']['pl'] for i in raw_dataset['train']]\n",
    "y = [i['translation']['en'] for i in raw_dataset['train']]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f'train size: {len(x_train)}, valid size: {len(x_valid)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train size: 3221, valid size: 806\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_ds = dataset.TranslationDataset(x_train, y_train, tokenizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, CFG.train_batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = CFG.lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "engine.train_fn(model, optimizer, train_dl, device, scheduler=None)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4aea93da1e9345ebae9112e83011906c"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('ml': conda)"
  },
  "interpreter": {
   "hash": "94e574b0ff762fa2604e2dda0d42a42ee05e68ff187669f28abf9be9211e1e6e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}