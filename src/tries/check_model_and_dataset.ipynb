{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('ml': conda)"
  },
  "interpreter": {
   "hash": "94e574b0ff762fa2604e2dda0d42a42ee05e68ff187669f28abf9be9211e1e6e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from datasets import load_dataset, load_metric\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset = load_dataset(\"europa_eac_tm\", language_pair=(\"pl\", \"en\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration pl2en-0da2ec5e9ea613fc\n",
      "Reusing dataset europa_eac_tm (/home/bartek/.cache/huggingface/datasets/europa_eac_tm/pl2en-0da2ec5e9ea613fc/0.0.0/955b2501a836c2ea49cfe3e719aec65dcbbc3356bbbe53cf46f08406eb77386a)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'sentence_type'],\n",
       "        num_rows: 4027\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "metric = load_metric(\"sacrebleu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "metric"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Metric(name: \"sacrebleu\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: \"\"\"\n",
       "Produces BLEU scores along with its sufficient statistics\n",
       "from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions: The system stream (a sequence of segments).\n",
       "    references: A list of one or more reference streams (each a sequence of segments).\n",
       "    smooth_method: The smoothing method to use. (Default: 'exp').\n",
       "    smooth_value: The smoothing value. Only valid for 'floor' and 'add-k'. (Defaults: floor: 0.1, add-k: 1).\n",
       "    tokenize: Tokenization method to use for BLEU. If not provided, defaults to 'zh' for Chinese, 'ja-mecab' for\n",
       "        Japanese and '13a' (mteval) otherwise.\n",
       "    lowercase: Lowercase the data. If True, enables case-insensitivity. (Default: False).\n",
       "    force: Insist that your tokenized input is actually detokenized.\n",
       "\n",
       "Returns:\n",
       "    'score': BLEU score,\n",
       "    'counts': Counts,\n",
       "    'totals': Totals,\n",
       "    'precisions': Precisions,\n",
       "    'bp': Brevity penalty,\n",
       "    'sys_len': predictions length,\n",
       "    'ref_len': reference length,\n",
       "\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
       "    >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n",
       "    >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
       "    >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
       "    >>> print(round(results[\"score\"], 1))\n",
       "    100.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dataset['train'][2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'translation': {'en': \"The grant application will be processed by computer. All personal data (such as names, addresses, CVs, etc.) will be processed in accordance with Regulation (EC) No 45/2001 of the European Parliament and of the Council of 18 December 2000 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data. Information provided by the applicants necessary in order to assess their grant application will be processed solely for that purpose by the department responsible for the programme concerned. On the applicant's request, personal data may be sent to the applicant to be corrected or completed. Any question relating to these data, should be addressed to the appropriate Agency to which the form must be submitted. Beneficiaries may lodge a complaint against the processing of their personal data with the European Data Protection Supervisor at anytime.\",\n",
       "  'pl': 'Wniosek o dofinansowanie będzie przetwarzany elektronicznie. Wszystkie dane osobowe (takie jak imię i nazwisko, adres i CV, itp. ) przetwarzane będą zgodnie z Rozporządzeniem KE nr 45/2001 Parlamentu Europejskiego oraz Rady z dn. 18 grudnia 2000 o ochronie osób fizycznych w związku z przetwarzaniem danych osobowych przez instytucje i organy Wspólnotowe i o swobodzie przepływu takich danych, jak również zgodnie z ustawą z dnia 29 sierpnia 1997 r. o ochronie danych osobowych (Dz. U. z 2002 r. Nr 101, poz. 926 ze zm.). Informacje podane przez osoby wnioskujące potrzebne w celu oceny składanego wniosku wykorzystywane będą jedynie we wspomnianym celu przez wydział odpowiedzialny za dany program. Na żądanie wnioskodawcy, dane osobowe mogą zostać wysłane do wnioskodawcy w celu poprawienia bądź uzupełnienia. Wszelkie zapytania dotyczące danych, powinny być kierowane do właściwej Agencji, do której należy składać wniosek. W sprawach związanych z przetwarzaniem danych osobowych Beneficjenci mają prawo odwołać się w dowolnym momencie do Europejskiego Inspektora Ochrony Danych.'},\n",
       " 'sentence_type': 0}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-pl-en\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tokenizer.max_len_single_sentence"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "if not os.path.exists('model_checkpoints/base_model/'):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "else:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained('model_checkpoints/base_model/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "model.save_pretrained('model_checkpoints/base_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# sample_input = dataset['train'][2]['translation']['pl']\n",
    "# sample_output = dataset['train'][2]['translation']['en']\n",
    "sample_input = \"Jak masz na imię?\"\n",
    "sample_output = \"What's your name?\"\n",
    "print(sample_input)\n",
    "print(sample_output)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Jak masz na imię?\n",
      "What's your name?\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "tokenizer.encode_plus(sample_input)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [295, 669, 22, 2552, 7, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "print(tokenizer.encode_plus(sample_output))\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer.encode_plus(sample_output))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'input_ids': [39, 6139, 6, 9, 15, 23, 1943, 22, 1326, 7, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [112, 6, 9, 79, 653, 7, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "tokenizer.vocab_size"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "63430"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "sample_input = tokenizer(sample_input, return_tensors='pt')\n",
    "sample_output = tokenizer(sample_output, return_tensors='pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "sample_input"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 295,  669,   22, 2552,    7,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "model.eval()\n",
    "output = model(**sample_input, decoder_input_ids=sample_output.input_ids, labels=sample_output.input_ids)\n",
    "# output = model.generate(**sample_input)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "output = np.argmax(output.logits.detach().cpu().numpy()[0], axis=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[63429,   112,     6,     9,    79,   653,     7,     0]])"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "output.logits"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.8370, -5.2278,  1.4809,  ..., -5.3075, -5.2583,  0.0000],\n",
       "         [ 1.4559, -6.5947, -0.2945,  ..., -6.3565, -6.2591,  0.0000],\n",
       "         [ 1.9986, -3.5359,  0.5771,  ..., -3.5303, -3.4807,  0.0000],\n",
       "         ...,\n",
       "         [ 0.3046, -8.3837, -0.0799,  ..., -8.3960, -8.4359,  0.0000],\n",
       "         [10.1125, -3.1985,  3.5722,  ..., -3.1705, -3.2222,  0.0000],\n",
       "         [ 4.3860, -5.4627,  3.3804,  ..., -5.1392, -4.9693,  0.0000]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "output = output.logits.detach().cpu().numpy()[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "import numpy as np\n",
    "output = np.argmax(output, axis=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "output = tokenizer.decode(output, skip_special_tokens=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "sample_output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  39, 6139,    6,    9,   15,   23, 1943,   22, 1326,    7,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "output == sample_output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'W?S your?? name??'"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.forward"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}